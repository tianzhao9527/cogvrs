# ğŸ” Cogvrs å®é™…ç³»ç»Ÿæœºåˆ¶è§£æ

## âš ï¸ é‡è¦æ›´æ­£ï¼šå®é™…vsç†è®º

é€šè¿‡æ£€æŸ¥å®é™…ä»£ç ï¼Œæˆ‘å‘ç°ä¹‹å‰çš„ä¸€äº›æŠ€æœ¯æè¿°è¿‡äºç†æƒ³åŒ–ã€‚ä»¥ä¸‹æ˜¯åŸºäºçœŸå®ä»£ç çš„å‡†ç¡®åˆ†æï¼š

---

## ğŸ§  çœŸå®çš„ç¥ç»ç½‘ç»œå®ç°

### å®é™…ç½‘ç»œæ¶æ„
```python
# ä» neural_brain.py å®é™…é…ç½®
input_size = 20        # è¾“å…¥ç»´åº¦
hidden_sizes = [32, 16] # ä¸¤ä¸ªéšè—å±‚
output_size = 8        # è¾“å‡ºç»´åº¦
activation = 'tanh'    # éšè—å±‚æ¿€æ´»å‡½æ•°
output_activation = 'sigmoid'  # è¾“å‡ºå±‚æ¿€æ´»å‡½æ•°
```

### çœŸå®çš„å†³ç­–æµç¨‹
```python
# SimpleAgent.update() ä¸­çš„å®é™…æµç¨‹ï¼š
def update(self, dt, world_state, nearby_agents, nearby_resources):
    # 1. åŸºç¡€ä»£è°¢ï¼ˆç®€åŒ–ç‰ˆï¼‰
    self._apply_metabolism(dt)
    
    # 2. æ„ŸçŸ¥ç¯å¢ƒï¼ˆæœ‰é™ä¿¡æ¯ï¼‰
    perception_data = self._perceive_environment(world_state, nearby_agents, nearby_resources)
    
    # 3. ç¥ç»ç½‘ç»œå†³ç­–
    neural_input = self._encode_perception(perception_data)
    neural_output = self.brain.predict(neural_input)
    
    # 4. è¡Œä¸ºç³»ç»Ÿå†³ç­–ï¼ˆä¸»è¦å†³ç­–æœºåˆ¶ï¼‰
    agent_state = self._get_agent_state()
    action = self.behavior_system.decide_action(agent_state, world_state, nearby_agents, nearby_resources)
```

**å…³é”®å‘ç°**: å®é™…ä¸Šæ˜¯**è¡Œä¸ºç³»ç»Ÿ**åœ¨ä¸»å¯¼å†³ç­–ï¼Œè€Œä¸æ˜¯ç¥ç»ç½‘ç»œï¼

---

## âš¡ å®é™…çš„èƒ½é‡ç³»ç»Ÿ

### çœŸå®çš„ä»£è°¢æœºåˆ¶
```python
def _apply_metabolism(self, dt):
    # å®é™…çš„èƒ½é‡æ¶ˆè€—è®¡ç®—
    base_consumption = 0.5 * dt                          # åŸºç¡€ä»£è°¢
    movement_consumption = self.velocity.magnitude() * 0.1 * dt  # ç§»åŠ¨æ¶ˆè€—
    brain_consumption = self.brain.calculate_complexity() * 0.01 * dt  # æ€è€ƒæ¶ˆè€—
    
    total_consumption = base_consumption + movement_consumption + brain_consumption
    self.energy = max(0, self.energy - total_consumption)
    
    # å¥åº·ä¸èƒ½é‡å…³è”
    if self.energy < 20:
        self.health -= 1.0 * dt  # ä½èƒ½é‡æŸå®³å¥åº·
    elif self.energy > 80:
        self.health = min(self.max_health, self.health + 0.5 * dt)  # é«˜èƒ½é‡æ¢å¤å¥åº·
```

**å®é™…æœºåˆ¶**: 
- åŸºç¡€ä»£è°¢: 0.5/ç§’
- ç§»åŠ¨æ¶ˆè€—: é€Ÿåº¦ Ã— 0.1
- å¤§è„‘æ¶ˆè€—: ç½‘ç»œå¤æ‚åº¦ Ã— 0.01
- èƒ½é‡å½±å“å¥åº·ï¼Œä½†å¥åº·ä¸ç›´æ¥å½±å“èƒ½é‡

---

## ğŸ­ å®é™…çš„è¡Œä¸ºç³»ç»Ÿ

### çœŸå®çš„åŠ¨æœºç³»ç»Ÿ
```python
# behavior.py ä¸­çš„å®é™…åŠ¨æœº
self.motivations = {
    'hunger': Motivation('hunger', 0.3, 0.02, 0.6),      # é¥¥é¥¿
    'energy': Motivation('energy', 0.2, 0.01, 0.7),     # èƒ½é‡éœ€æ±‚
    'curiosity': Motivation('curiosity', 0.8, 0.005, 0.5), # å¥½å¥‡å¿ƒ
    'social': Motivation('social', 0.4, 0.008, 0.6),    # ç¤¾äº¤éœ€æ±‚
    'reproduction': Motivation('reproduction', 0.1, 0.001, 0.9), # ç¹æ®–
    'safety': Motivation('safety', 0.3, 0.005, 0.8)     # å®‰å…¨éœ€æ±‚
}
```

### çœŸå®çš„å†³ç­–é€»è¾‘
```python
def decide_action(self, agent_state, world_info, nearby_agents, nearby_resources):
    # 1. æ›´æ–°åŠ¨æœºå¼ºåº¦
    self._update_motivations(agent_state)
    
    # 2. é€‰æ‹©æœ€å¼ºåŠ¨æœº
    strongest_motivation = max(self.motivations.values(), key=lambda m: m.value if m.is_active() else 0)
    
    # 3. åŸºäºåŠ¨æœºé€‰æ‹©è¡ŒåŠ¨
    action = self._choose_action_for_motivation(strongest_motivation, ...)
    
    return action
```

**å®é™…æœºåˆ¶**: 
- åŸºäº**è§„åˆ™çš„åŠ¨æœºç³»ç»Ÿ**ï¼Œä¸æ˜¯ç¥ç»ç½‘ç»œå†³ç­–
- ç®€å•çš„æœ€å¤§å€¼é€‰æ‹©ï¼Œæ²¡æœ‰å¤æ‚çš„æ•ˆç”¨è®¡ç®—
- åŠ¨æœºä¼šè‡ªåŠ¨è¡°å‡å’Œæ ¹æ®çŠ¶æ€æ›´æ–°

---

## ğŸ¤ å®é™…çš„ç¤¾äº¤ç³»ç»Ÿ

### çœŸå®çš„ç¤¾äº¤è¡Œä¸º
```python
def _handle_social_interaction(self, nearby_agents, agent_state):
    if not nearby_agents:
        return self._random_movement(agent_state)
    
    social_preference = self.behavior_preferences['social_activity']  # ä¸ªæ€§ç‰¹å¾
    cooperation_preference = self.behavior_preferences['cooperation']
    
    # é€‰æ‹©æœ€è¿‘çš„æ™ºèƒ½ä½“
    agent_pos = Vector2D(agent_state['position'][0], agent_state['position'][1])
    closest_agent = min(nearby_agents, key=lambda a: agent_pos.distance_to(Vector2D(a.position.x, a.position.y)))
    
    if social_preference > 0.6:
        # é«˜ç¤¾äº¤å€¾å‘ï¼šä¸»åŠ¨æ¥è¿‘
        return Action(ActionType.COMMUNICATE, target=Vector2D(closest_agent.position.x, closest_agent.position.y))
    else:
        # ä½ç¤¾äº¤å€¾å‘ï¼šéšæœºç§»åŠ¨
        return self._random_movement(agent_state)
```

**å®é™…æœºåˆ¶**: 
- åŸºäºè·ç¦»çš„ç®€å•ç¤¾äº¤
- ä¸ªæ€§ç‰¹å¾å½±å“ç¤¾äº¤å€¾å‘
- æ²¡æœ‰å¤æ‚çš„ä¿¡æ¯ä¼ é€’æˆ–å­¦ä¹ 

---

## ğŸ§¬ å®é™…çš„ç¹æ®–ç³»ç»Ÿ

### çœŸå®çš„ç¹æ®–é€»è¾‘
```python
# åœ¨ GUI çš„ _handle_reproduction ä¸­ï¼š
def _handle_reproduction(self, agents):
    new_agents = []
    
    for agent in agents:
        # ç®€å•çš„ç¹æ®–æ¡ä»¶æ£€æŸ¥
        if (agent.energy > 80 and 
            agent.age > 50 and 
            agent.offspring_count < 3 and
            len(agents) < 50):
            
            # å¯»æ‰¾ç¹æ®–ä¼™ä¼´
            nearby_agents = self._get_nearby_agents(agent)
            suitable_partners = [a for a in nearby_agents if a.energy > 70 and a.age > 40 and a.offspring_count < 3]
            
            if suitable_partners and len(new_agents) < 5:
                # ç¹æ®–
                child = agent.clone(mutation_rate=0.1)
                child.birth_time = self.time_manager.current_step
                new_agents.append(child)
                
                # æ›´æ–°çˆ¶æ¯çŠ¶æ€
                agent.offspring_count += 1
                agent.energy -= 30
```

**å®é™…æœºåˆ¶**: 
- åŸºäºç®€å•æ¡ä»¶çš„æ— æ€§ç¹æ®–ï¼ˆå…‹éš†+çªå˜ï¼‰
- æ²¡æœ‰å®é™…çš„ç¥ç»ç½‘ç»œäº¤å‰
- ç¹æ®–ä¸»è¦æ˜¯å‚æ•°å¤åˆ¶å’Œå°å¹…çªå˜

---

## ğŸ’ å®é™…çš„èµ„æºç³»ç»Ÿ

### çœŸå®çš„èµ„æºæœºåˆ¶
```python
# ä»ä¸–ç•Œç”Ÿæˆå’Œèµ„æºæ¶ˆè€—æ¥çœ‹ï¼š
def generate_resources(self):
    # ç®€å•çš„éšæœºèµ„æºç”Ÿæˆ
    total_resources = int(world_size[0] * world_size[1] * density)
    
    for _ in range(total_resources):
        resource = Resource(
            position=random_position(),
            value=random.uniform(10, 50),
            type='food'  # ä¸»è¦æ˜¯é£Ÿç‰©ç±»å‹
        )
```

**å®é™…æœºåˆ¶**: 
- ä¸»è¦æ˜¯é£Ÿç‰©èµ„æº
- å›ºå®šå€¼çš„èµ„æºç‚¹
- ç®€å•çš„éšæœºåˆ†å¸ƒ

---

## ğŸ¨ å®é™…çš„é¢œè‰²ç³»ç»Ÿ

### çœŸå®çš„é¢œè‰²ç¼–ç 
```python
# ä» world_view.py çš„æ¸²æŸ“é€»è¾‘æ¥çœ‹ï¼Œé¢œè‰²ä¸»è¦åŸºäºï¼š
def get_agent_color(agent):
    # åŸºäºå¥åº·çŠ¶æ€çš„ç®€å•é¢œè‰²æ˜ å°„
    health_ratio = agent.health / 100.0
    energy_ratio = agent.energy / agent.max_energy
    
    # ç®€å•çš„ç»¿-é»„-çº¢æ¸å˜
    if energy_ratio > 0.7:
        return (0, 255, 0)      # ç»¿è‰² - å¥åº·
    elif energy_ratio > 0.4:
        return (255, 255, 0)    # é»„è‰² - ä¸€èˆ¬
    else:
        return (255, 0, 0)      # çº¢è‰² - å±é™©
```

**å®é™…æœºåˆ¶**: 
- ä¸»è¦åŸºäºèƒ½é‡æ°´å¹³çš„ç®€å•é¢œè‰²æ˜ å°„
- ç»¿è‰²(å¥åº·) â†’ é»„è‰²(ä¸€èˆ¬) â†’ çº¢è‰²(å±é™©)
- æ²¡æœ‰å¤æ‚çš„çŠ¶æ€é¢œè‰²ç¼–ç 

---

## ğŸ“Š å®é™…æŒ‡æ ‡çš„çœŸå®å«ä¹‰

### 1. **Agents (æ™ºèƒ½ä½“æ•°é‡)**
- **è®¡ç®—**: `len([agent for agent in self.agents if agent.alive])`
- **æ­»äº¡æ¡ä»¶**: `energy <= 0` æˆ– `health <= 0`
- **å«ä¹‰**: ç®€å•çš„å­˜æ´»è®¡æ•°

### 2. **Avg Energy (å¹³å‡èƒ½é‡)**
- **è®¡ç®—**: `sum(energies) / len(energies)`
- **èŒƒå›´**: 0-150ï¼ˆmax_energyé™åˆ¶ï¼‰
- **æ¶ˆè€—**: åŸºç¡€ä»£è°¢0.5/ç§’ + ç§»åŠ¨æ¶ˆè€— + å¤§è„‘æ¶ˆè€—
- **æ¢å¤**: é€šè¿‡åƒé£Ÿç‰©èµ„æº

### 3. **Avg Age (å¹³å‡å¹´é¾„)** 
- **è®¡ç®—**: `sum(ages) / len(ages)`
- **å¢é•¿**: æ¯ä¸ªæ—¶é—´æ­¥ +1
- **å½±å“**: å¹´é¾„>200åå¥åº·åŠ é€Ÿè¡°å‡

### 4. **Avg Health (å¹³å‡å¥åº·)**
- **è®¡ç®—**: `sum(healths) / len(healths)`
- **èŒƒå›´**: 0-100
- **å½±å“å› ç´ **: 
  - èƒ½é‡<20: å¥åº·-1.0/ç§’
  - èƒ½é‡>80: å¥åº·+0.5/ç§’
  - å¹´é¾„>200: å¥åº·-(age-200)*0.01/ç§’

### 5. **Offspring (åä»£æ€»æ•°)**
- **è®¡ç®—**: `sum(agent.offspring_count for agent in alive_agents)`
- **ç¹æ®–æ¡ä»¶**: èƒ½é‡>80, å¹´é¾„>50, åä»£<3, ç§ç¾¤<50
- **æœºåˆ¶**: æ— æ€§ç¹æ®–ï¼ˆå…‹éš†+çªå˜ï¼‰

### 6. **Interactions (ç¤¾äº¤äº’åŠ¨)**
- **è®¡ç®—**: `sum(agent.social_interactions for agent in alive_agents)`
- **è§¦å‘**: æ™ºèƒ½ä½“é è¿‘æ—¶åŸºäºç¤¾äº¤åå¥½
- **æ•ˆæœ**: ä¸»è¦æ˜¯è®¡æ•°å™¨ï¼Œæ²¡æœ‰å®é™…ä¿¡æ¯äº¤æ¢

### 7. **Resources (èµ„æºæ•°é‡)**
- **è®¡ç®—**: `world_state['num_resources']`
- **ç±»å‹**: ä¸»è¦æ˜¯é£Ÿç‰©
- **å†ç”Ÿ**: ç®€å•çš„æ¦‚ç‡å†ç”Ÿ

### 8. **FPS (å¸§ç‡)**
- **è®¡ç®—**: `1.0 / avg_frame_time`
- **å½±å“å› ç´ **: æ™ºèƒ½ä½“æ•°é‡ã€æ¸²æŸ“å¤æ‚åº¦
- **ä¼˜åŒ–**: è·³å¸§æ¸²æŸ“ã€åå°ç¼“å†²

---

## ğŸ¯ å…³é”®å‘ç°æ€»ç»“

### âœ… å®é™…å®ç°çš„åŠŸèƒ½
1. **åŸºæœ¬ç”Ÿå‘½ç³»ç»Ÿ**: èƒ½é‡ã€å¥åº·ã€å¹´é¾„ã€æ­»äº¡
2. **åŠ¨æœºé©±åŠ¨è¡Œä¸º**: 6ç§åŸºæœ¬åŠ¨æœºçš„è§„åˆ™ç³»ç»Ÿ
3. **ç®€å•ç¤¾äº¤**: åŸºäºè·ç¦»å’Œä¸ªæ€§çš„æ¥è§¦
4. **æ— æ€§ç¹æ®–**: å…‹éš†+çªå˜çš„è¿›åŒ–
5. **èµ„æºç³»ç»Ÿ**: é£Ÿç‰©çš„æ¶ˆè€—å’Œå†ç”Ÿ
6. **åŸºç¡€å­¦ä¹ **: ç¥ç»ç½‘ç»œçš„ç®€å•å¼ºåŒ–å­¦ä¹ 

### âŒ æœªå®é™…å®ç°çš„åŠŸèƒ½
1. **å¤æ‚ç¥ç»ç½‘ç»œå†³ç­–**: ä¸»è¦è¿˜æ˜¯è§„åˆ™ç³»ç»Ÿ
2. **æœ‰æ€§ç¹æ®–**: æ²¡æœ‰çœŸæ­£çš„åŸºå› äº¤å‰
3. **å¤æ‚ç¤¾äº¤ç½‘ç»œ**: æ²¡æœ‰ä¿¡æ¯ä¼ é€’æˆ–ç¾¤ä½“å†³ç­–
4. **é«˜çº§å­¦ä¹ **: æ²¡æœ‰å¤æ‚çš„çŸ¥è¯†è½¬ç§»
5. **ç¯å¢ƒå˜åŒ–**: é™æ€çš„ä¸–ç•Œç¯å¢ƒ
6. **ç¾¤ä½“æ™ºæ…§**: æ²¡æœ‰é›†ä½“è¡Œä¸ºæ¶Œç°

### ğŸ”¬ ç³»ç»Ÿçš„çœŸå®å¤æ‚åº¦
Cogvrsæ˜¯ä¸€ä¸ª**ä¸­ç­‰å¤æ‚åº¦çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š
- **è§„åˆ™é©±åŠ¨**: è€Œéçº¯AIé©±åŠ¨
- **ç®€å•äº¤äº’**: è€Œéå¤æ‚ç¤¾äº¤ç½‘ç»œ
- **åŸºç¡€è¿›åŒ–**: è€Œéé«˜çº§é—ä¼ ç®—æ³•
- **ç»Ÿè®¡è§‚å¯Ÿ**: è€Œéæ™ºèƒ½åˆ†æ

å°½ç®¡å¦‚æ­¤ï¼Œè¿™ä¸ªç³»ç»Ÿä»ç„¶èƒ½å¤Ÿå±•ç°æœ‰è¶£çš„**æ¶Œç°è¡Œä¸º**å’Œ**é›†ä½“åŠ¨æ€**ï¼Œæ˜¯å­¦ä¹ å’Œç ”ç©¶äººå·¥ç”Ÿå‘½çš„å¾ˆå¥½èµ·ç‚¹ï¼ğŸš€

---

## ğŸ¨ é¢œè‰²è§‚å¯ŸæŒ‡å—ï¼ˆå®é™…ç‰ˆï¼‰

- **ğŸŸ¢ ç»¿è‰²**: èƒ½é‡ > 70% - å¥åº·çŠ¶æ€
- **ğŸŸ¡ é»„è‰²**: èƒ½é‡ 40%-70% - ä¸€èˆ¬çŠ¶æ€  
- **ğŸ”´ çº¢è‰²**: èƒ½é‡ < 40% - å±é™©çŠ¶æ€

**è§‚å¯ŸæŠ€å·§**: 
- ç»¿è‰²æ™ºèƒ½ä½“æ›´æ´»è·ƒï¼Œç§»åŠ¨æ›´å¤š
- çº¢è‰²æ™ºèƒ½ä½“è¶‹å‘äºå¯»æ‰¾é£Ÿç‰©
- é»„è‰²æ™ºèƒ½ä½“åœ¨è¿‡æ¸¡çŠ¶æ€ï¼Œè¡Œä¸ºç›¸å¯¹å¹³è¡¡